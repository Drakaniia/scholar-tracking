# ============================================================================
# LOAD BALANCING CONFIGURATION
# ============================================================================
# Advanced upstream configurations for scaling the application
# ============================================================================

# -----------------------------------------------------------------------------
# NEXT.JS APPLICATION CLUSTER
# -----------------------------------------------------------------------------
# Use this for multiple Next.js instances
upstream nextjs_cluster {
    # Load Balancing Methods:
    # - round-robin (default): Distributes requests evenly
    # - least_conn: Routes to server with fewest connections
    # - ip_hash: Sticky sessions based on client IP
    # - hash: Custom hash key for session affinity

    # Using least_conn for optimal distribution
    least_conn;

    # Health check zone (requires ngx_http_upstream_hc_module - Nginx Plus only)
    # zone nextjs_cluster 64k;

    # Application servers
    # Weight: Higher = more traffic (default is 1)
    # max_fails: Failures before marking unavailable
    # fail_timeout: Time to wait before retrying failed server

    # Primary servers
    server 127.0.0.1:3000 weight=5 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:3001 weight=5 max_fails=3 fail_timeout=30s;

    # Secondary servers (lower weight)
    server 127.0.0.1:3002 weight=3 max_fails=3 fail_timeout=30s;

    # Backup server (only used when primary servers are down)
    server 127.0.0.1:3003 backup;

    # Mark server as permanently unavailable
    # server 127.0.0.1:3004 down;

    # Keepalive connections for connection pooling
    keepalive 64;
    keepalive_requests 1000;
    keepalive_timeout 60s;
}

# -----------------------------------------------------------------------------
# SESSION STICKY - IP HASH
# -----------------------------------------------------------------------------
# Use when application requires session persistence
upstream nextjs_sticky {
    ip_hash;

    server 127.0.0.1:3000 weight=5 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:3001 weight=5 max_fails=3 fail_timeout=30s;
    server 127.0.0.1:3002 weight=3 max_fails=3 fail_timeout=30s;

    keepalive 32;
}

# -----------------------------------------------------------------------------
# SESSION STICKY - COOKIE BASED (Nginx Plus)
# -----------------------------------------------------------------------------
# upstream nextjs_cookie_sticky {
#     zone sticky 64k;
#     sticky cookie srv_id expires=1h domain=.scholarship.example.com path=/;
#
#     server 127.0.0.1:3000;
#     server 127.0.0.1:3001;
# }

# -----------------------------------------------------------------------------
# HASH BASED ROUTING
# -----------------------------------------------------------------------------
# Routes requests based on a consistent hash of the URI
# Useful for caching scenarios
upstream nextjs_hash {
    hash $request_uri consistent;

    server 127.0.0.1:3000;
    server 127.0.0.1:3001;
    server 127.0.0.1:3002;

    keepalive 32;
}

# -----------------------------------------------------------------------------
# BLUE-GREEN DEPLOYMENT
# -----------------------------------------------------------------------------
# Switch between deployments with zero downtime
# Toggle by commenting/uncommenting
upstream nextjs_bluegreen {
    # BLUE environment (current production)
    server 127.0.0.1:3000 weight=100;
    server 127.0.0.1:3001 weight=100;

    # GREEN environment (new version) - mark as down initially
    server 127.0.0.1:3010 down;
    server 127.0.0.1:3011 down;

    keepalive 32;
}

# -----------------------------------------------------------------------------
# CANARY DEPLOYMENT
# -----------------------------------------------------------------------------
# Gradually shift traffic to new version
upstream nextjs_canary {
    # Stable version (90% traffic)
    server 127.0.0.1:3000 weight=90;
    server 127.0.0.1:3001 weight=90;

    # Canary version (10% traffic)
    server 127.0.0.1:3010 weight=10;

    keepalive 32;
}

# -----------------------------------------------------------------------------
# DATABASE CONNECTION POOL (for TCP proxying)
# -----------------------------------------------------------------------------
# Use in stream {} block for database load balancing
# upstream postgres_cluster {
#     least_conn;
#
#     # Primary (write)
#     server db-primary.example.com:5432 weight=10;
#
#     # Replicas (read)
#     server db-replica1.example.com:5432 weight=5;
#     server db-replica2.example.com:5432 weight=5;
# }

# -----------------------------------------------------------------------------
# WEBSOCKET BACKEND
# -----------------------------------------------------------------------------
upstream websocket_backend {
    # Use ip_hash for WebSocket connections to maintain connection affinity
    ip_hash;

    server 127.0.0.1:3000;
    server 127.0.0.1:3001;

    keepalive 32;
}

# -----------------------------------------------------------------------------
# API BACKEND (Separate if needed)
# -----------------------------------------------------------------------------
upstream api_backend {
    least_conn;

    server 127.0.0.1:3000;
    server 127.0.0.1:3001;

    # Longer keepalive for API connections
    keepalive 64;
    keepalive_requests 2000;
    keepalive_timeout 120s;
}

# -----------------------------------------------------------------------------
# HEALTH CHECK CONFIGURATION (Nginx Plus)
# -----------------------------------------------------------------------------
# Add to server block:
# location @healthcheck {
#     internal;
#     proxy_pass http://nextjs_cluster;
#     health_check interval=5s fails=3 passes=2 uri=/health;
# }

# -----------------------------------------------------------------------------
# ACTIVE HEALTH CHECKS (Open Source Alternative)
# -----------------------------------------------------------------------------
# Use a separate monitoring service (e.g., HAProxy, Keepalived) or
# implement with Lua module:
#
# location = /upstream-check {
#     content_by_lua_block {
#         local http = require "resty.http"
#         local httpc = http.new()
#         local res, err = httpc:request_uri("http://127.0.0.1:3000/health")
#         if not res or res.status ~= 200 then
#             ngx.status = 503
#             ngx.say("upstream unhealthy")
#             return
#         end
#         ngx.say("upstream healthy")
#     }
# }
